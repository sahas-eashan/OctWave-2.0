{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53ecef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Obesity Classification - Extra Trees Only (Optimized for 85%+ Accuracy)\n",
    "Focused approach with best feature engineering\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LOAD DATA\n",
    "# ============================================================================\n",
    "train_df = pd.read_csv('train.csv')\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Target distribution:\\n{train_df['Weight_Category'].value_counts()}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. ADVANCED FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "def create_enhanced_features(df):\n",
    "    \"\"\"Create extensive feature set with polynomial and interaction features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Core BMI features\n",
    "    df['BMI'] = df['Weight_Kg'] / ((df['Height_cm'] / 100) ** 2)\n",
    "    df['BMI_squared'] = df['BMI'] ** 2\n",
    "    df['BMI_cubed'] = df['BMI'] ** 3\n",
    "    df['BMI_log'] = np.log1p(df['BMI'])\n",
    "    df['BMI_sqrt'] = np.sqrt(df['BMI'])\n",
    "    \n",
    "    # Weight-Height ratios\n",
    "    df['Weight_Height_Ratio'] = df['Weight_Kg'] / df['Height_cm']\n",
    "    df['Weight_Height_Ratio_Sq'] = df['Weight_Height_Ratio'] ** 2\n",
    "    df['Height_Weight_Ratio'] = df['Height_cm'] / df['Weight_Kg']\n",
    "    \n",
    "    # Age features\n",
    "    df['Age_squared'] = df['Age_Years'] ** 2\n",
    "    df['Age_log'] = np.log1p(df['Age_Years'])\n",
    "    df['Age_BMI'] = df['Age_Years'] * df['BMI']\n",
    "    df['Age_Weight'] = df['Age_Years'] * df['Weight_Kg']\n",
    "    df['Age_Height'] = df['Age_Years'] * df['Height_cm']\n",
    "    \n",
    "    # Age categories (more robust approach with codes)\n",
    "    age_filled = df['Age_Years'].fillna(df['Age_Years'].median())\n",
    "    df['Age_Group'] = pd.cut(age_filled, bins=[0, 25, 35, 45, 100], labels=False)\n",
    "    df['Age_Group'] = df['Age_Group'].fillna(1).astype(int)\n",
    "    \n",
    "    # Lifestyle binary features\n",
    "    df['High_Cal'] = (df['High_Calorie_Food'] == 'yes').astype(int)\n",
    "    df['Low_Veg'] = (df['Vegetable_Intake'] < 2).astype(int)\n",
    "    df['Low_Water'] = (df['Water_Intake'] < 2).astype(int)\n",
    "    df['High_Screen'] = (df['Screen_Time_Hours'] > 4).astype(int)\n",
    "    \n",
    "    # Enhanced diet score with polynomial terms\n",
    "    df['Diet_Score'] = (\n",
    "        df['High_Cal'] * 4 +\n",
    "        (3 - df['Vegetable_Intake']).clip(0, 3) * 2.5 +\n",
    "        (3 - df['Water_Intake']).clip(0, 3) * 2 +\n",
    "        df['Meal_Frequency'] * 0.8\n",
    "    )\n",
    "    df['Diet_Score_Sq'] = df['Diet_Score'] ** 2\n",
    "    \n",
    "    # Activity features\n",
    "    activity_map = {'low': 0, 'medium': 1, 'high': 2}\n",
    "    df['Activity_Num'] = df['Physical_Activity_Level'].map(activity_map).fillna(0)\n",
    "    \n",
    "    if 'Activity_Level_Score' not in df.columns:\n",
    "        df['Activity_Level_Score'] = df['Activity_Num'].astype(float)\n",
    "    \n",
    "    df['Activity_Score_Sq'] = df['Activity_Level_Score'] ** 2\n",
    "    df['Sedentary'] = (df['High_Screen'] + (df['Activity_Level_Score'] < 1).astype(int))\n",
    "    \n",
    "    # Risk factors with better encoding\n",
    "    df['Family_Hist'] = (df['Family_History'] == 'yes').astype(int)\n",
    "    df['Smoking'] = (df['Smoking_Habit'] == 'yes').astype(int)\n",
    "    \n",
    "    alcohol_map = {'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
    "    df['Alcohol'] = df['Alcohol_Consumption'].map(alcohol_map).fillna(0)\n",
    "    \n",
    "    snack_map = {'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
    "    df['Snack'] = df['Snack_Frequency'].map(snack_map).fillna(1)\n",
    "    \n",
    "    if 'Family_Risk' not in df.columns:\n",
    "        df['Family_Risk'] = df['Family_Hist']\n",
    "    \n",
    "    # Enhanced risk score\n",
    "    df['Total_Risk'] = (\n",
    "        df['Family_Hist'] * 5 +\n",
    "        df['Family_Risk'] * 4 +\n",
    "        df['Smoking'] * 3.5 +\n",
    "        df['Alcohol'] * 2.5 +\n",
    "        df['Snack'] * 2 +\n",
    "        df['Diet_Score'] * 0.5 +\n",
    "        df['Sedentary'] * 3 -\n",
    "        df['Activity_Num'] * 2.5 -\n",
    "        df['Activity_Level_Score'] * 1.5\n",
    "    )\n",
    "    df['Total_Risk_Sq'] = df['Total_Risk'] ** 2\n",
    "    \n",
    "    # Gender\n",
    "    df['Gender_Male'] = (df['Gender'] == 'Male').astype(int)\n",
    "    \n",
    "    # Transport\n",
    "    df['Active_Transport'] = df['Commute_Mode'].isin(['Walking', 'Bike']).astype(int)\n",
    "    \n",
    "    # Critical interactions\n",
    "    df['BMI_Risk'] = df['BMI'] * df['Total_Risk']\n",
    "    df['BMI_Age'] = df['BMI'] * df['Age_Years']\n",
    "    df['BMI_Diet'] = df['BMI'] * df['Diet_Score']\n",
    "    df['BMI_Activity'] = df['BMI'] * df['Activity_Level_Score']\n",
    "    df['Diet_Activity_Gap'] = df['Diet_Score'] - df['Activity_Level_Score']\n",
    "    df['Risk_Activity_Ratio'] = df['Total_Risk'] / (df['Activity_Level_Score'] + 1)\n",
    "    \n",
    "    # Advanced interactions\n",
    "    df['Age_Risk'] = df['Age_Years'] * df['Total_Risk']\n",
    "    df['Gender_BMI'] = df['Gender_Male'] * df['BMI']\n",
    "    df['Family_BMI'] = df['Family_Hist'] * df['BMI']\n",
    "    df['Screen_Activity'] = df['Screen_Time_Hours'] * (3 - df['Activity_Level_Score'])\n",
    "    \n",
    "    # Lifestyle balance\n",
    "    df['Health_Score'] = (\n",
    "        df['Vegetable_Intake'] * 2 +\n",
    "        df['Water_Intake'] * 1.5 +\n",
    "        df['Activity_Level_Score'] * 3 -\n",
    "        df['High_Cal'] * 3 -\n",
    "        df['Screen_Time_Hours'] * 0.5 -\n",
    "        df['Snack'] * 1.5\n",
    "    )\n",
    "    df['Lifestyle_Balance'] = df['Health_Score'] - df['Diet_Score']\n",
    "    \n",
    "    # Binning important continuous features\n",
    "    bmi_filled = df['BMI'].fillna(df['BMI'].median())\n",
    "    df['BMI_Category'] = pd.cut(bmi_filled, bins=[0, 18.5, 25, 30, 35, 100], labels=False)\n",
    "    df['BMI_Category'] = df['BMI_Category'].fillna(2).astype(int)\n",
    "    \n",
    "    screen_filled = df['Screen_Time_Hours'].fillna(df['Screen_Time_Hours'].median())\n",
    "    df['Screen_Category'] = pd.cut(screen_filled, bins=[0, 2, 4, 6, 24], labels=False)\n",
    "    df['Screen_Category'] = df['Screen_Category'].fillna(1).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = create_enhanced_features(train_df)\n",
    "print(f\"✓ Enhanced features created: {train_df.shape[1]} columns\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. PREPROCESSING\n",
    "# ============================================================================\n",
    "def prepare_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    if is_train:\n",
    "        X = df.drop(['PersonID', 'Weight_Category'], axis=1)\n",
    "        y = df['Weight_Category']\n",
    "    else:\n",
    "        X = df.drop(['PersonID'], axis=1)\n",
    "        y = None\n",
    "    \n",
    "    # Encode categoricals\n",
    "    for col in X.select_dtypes(include=['object', 'category']).columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "    \n",
    "    X = X.fillna(X.median(numeric_only=True)).replace([np.inf, -np.inf], 0)\n",
    "    return X, y\n",
    "\n",
    "X, y = prepare_data(train_df, is_train=True)\n",
    "\n",
    "# Scale features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining: {len(X_train)}, Validation: {len(X_val)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. TRAIN EXTRA TREES WITH MULTIPLE CONFIGURATIONS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING EXTRA TREES WITH DIFFERENT CONFIGURATIONS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        'name': 'Extra Trees - Config 1 (Balanced)',\n",
    "        'params': {\n",
    "            'n_estimators': 500,\n",
    "            'max_depth': 30,\n",
    "            'min_samples_split': 5,\n",
    "            'min_samples_leaf': 2,\n",
    "            'max_features': 'sqrt',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Extra Trees - Config 2 (Deep)',\n",
    "        'params': {\n",
    "            'n_estimators': 600,\n",
    "            'max_depth': 35,\n",
    "            'min_samples_split': 3,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'random_state': 123,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Extra Trees - Config 3 (Wide)',\n",
    "        'params': {\n",
    "            'n_estimators': 700,\n",
    "            'max_depth': 28,\n",
    "            'min_samples_split': 4,\n",
    "            'min_samples_leaf': 2,\n",
    "            'max_features': 'log2',\n",
    "            'random_state': 456,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Extra Trees - Config 4 (Conservative)',\n",
    "        'params': {\n",
    "            'n_estimators': 800,\n",
    "            'max_depth': 25,\n",
    "            'min_samples_split': 8,\n",
    "            'min_samples_leaf': 3,\n",
    "            'max_features': 'sqrt',\n",
    "            'random_state': 789,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "models = []\n",
    "results = []\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Training: {config['name']}...\")\n",
    "    et = ExtraTreesClassifier(**config['params'])\n",
    "    et.fit(X_train, y_train)\n",
    "    pred = et.predict(X_val)\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    \n",
    "    models.append((config['name'], et))\n",
    "    results.append({'Model': config['name'], 'Accuracy': acc})\n",
    "    \n",
    "    print(f\"  Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXTRA TREES CONFIGURATIONS COMPARISON\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['Accuracy %'] = results_df['Accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#27ae60' if acc >= 0.85 else '#2ecc71' if acc >= 0.80 else '#3498db' \n",
    "          for acc in results_df['Accuracy']]\n",
    "bars = plt.barh(results_df['Model'], results_df['Accuracy'], color=colors)\n",
    "plt.xlabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.title('Extra Trees Configurations - Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0.70, 1.0)\n",
    "for bar, acc in zip(bars, results_df['Accuracy']):\n",
    "    plt.text(acc + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "             f'{acc:.4f} ({acc*100:.2f}%)', va='center', fontweight='bold')\n",
    "plt.axvline(x=0.80, color='orange', linestyle='--', linewidth=2, label='80% Target')\n",
    "plt.axvline(x=0.85, color='green', linestyle='--', linewidth=2, label='85% Target')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. ENSEMBLE OF EXTRA TREES (Voting)\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING ENSEMBLE OF ALL EXTRA TREES MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Collect all predictions\n",
    "all_preds = []\n",
    "for name, model in models:\n",
    "    pred = model.predict(X_val)\n",
    "    all_preds.append(pred)\n",
    "\n",
    "# Majority voting\n",
    "ensemble_preds_array = np.vstack(all_preds)\n",
    "final_ensemble_pred = pd.DataFrame(ensemble_preds_array).mode(axis=0).iloc[0].to_numpy()\n",
    "ensemble_acc = accuracy_score(y_val, final_ensemble_pred)\n",
    "\n",
    "print(f\"\\n✓ Extra Trees Ensemble Accuracy: {ensemble_acc:.4f} ({ensemble_acc*100:.2f}%)\")\n",
    "\n",
    "# Display confusion matrix for best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = [m for n, m in models if n == best_model_name][0]\n",
    "best_pred = best_model.predict(X_val)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"CONFUSION MATRIX - {best_model_name}\")\n",
    "print(f\"{'='*70}\")\n",
    "cm = confusion_matrix(y_val, best_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=sorted(y_val.unique()), \n",
    "            yticklabels=sorted(y_val.unique()))\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, best_pred))\n",
    "\n",
    "# ============================================================================\n",
    "# 8. TRAIN BEST MODELS ON FULL DATA\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING ALL MODELS ON FULL DATA\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "final_models_full = []\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Training {config['name']} on full data...\")\n",
    "    et = ExtraTreesClassifier(**config['params'])\n",
    "    et.fit(X_scaled, y)\n",
    "    final_models_full.append((config['name'], et))\n",
    "\n",
    "print(\"✓ Training complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. GENERATE TEST PREDICTIONS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATING TEST PREDICTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "test_df_raw = pd.read_csv('test.csv')\n",
    "print(f\"Test data shape: {test_df_raw.shape}\")\n",
    "\n",
    "test_df = create_enhanced_features(test_df_raw.copy())\n",
    "X_test, _ = prepare_data(test_df, is_train=False)\n",
    "\n",
    "# Align columns\n",
    "missing_cols = set(X.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[X.columns]\n",
    "\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Predict with all models\n",
    "all_test_preds = []\n",
    "for name, model in final_models_full:\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    all_test_preds.append(pred)\n",
    "\n",
    "# Ensemble prediction (majority voting)\n",
    "test_preds_array = np.vstack(all_test_preds)\n",
    "final_predictions = pd.DataFrame(test_preds_array).mode(axis=0).iloc[0].to_numpy()\n",
    "\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(pd.Series(final_predictions).value_counts().sort_index())\n",
    "\n",
    "# ============================================================================\n",
    "# 10. CREATE SUBMISSION\n",
    "# ============================================================================\n",
    "submission = pd.DataFrame({\n",
    "    'PersonID': test_df_raw['PersonID'],\n",
    "    'Weight_Category': final_predictions\n",
    "})\n",
    "submission.to_csv('submission_extratrees.csv', index=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUBMISSION FILE CREATED\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"File: submission_extratrees.csv\")\n",
    "print(f\"Predictions: {len(submission)}\")\n",
    "print(f\"\\nFirst 10:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Best Single Config: {best_model_name} ({results_df.iloc[0]['Accuracy']*100:.2f}%)\")\n",
    "print(f\"Ensemble Accuracy (val): {ensemble_acc*100:.2f}%\")\n",
    "print(f\"Number of Models: {len(final_models_full)}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"\\n✅ Extra Trees submission ready!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
